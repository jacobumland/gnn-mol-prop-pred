{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6e2c221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from ogb.graphproppred import DglGraphPropPredDataset\n",
    "from data_functions import create_smiles_files, handle_raw_data, get_processed_data, get_split_data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from igraph import *\n",
    "import sys\n",
    "# sys.path.append('../models')\n",
    "# from model_functions import get_split_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0b24ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle warnings\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3854894",
   "metadata": {},
   "source": [
    "### Graph Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4834c0a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://snap.stanford.edu/ogb/data/graphproppred/csv_mol_download/hiv.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloaded 0.00 GB: 100%|██████████| 3/3 [00:03<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ogbg-molhiv dataset/hiv.zip\n",
      "Loading necessary files...\n",
      "This might take a while.\n",
      "Processing graphs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41127/41127 [00:01<00:00, 24075.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting graphs into DGL objects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41127/41127 [00:45<00:00, 901.46it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving...\n"
     ]
    }
   ],
   "source": [
    "# load graph data\n",
    "# if run for 1st time, creates \"ogbg-molhiv dataset\" folder in \"data\" folder\n",
    "dataset = DglGraphPropPredDataset(name = \"ogbg-molhiv\", root = \"ogbg-molhiv dataset/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dd33fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the data is comprised of 41127 molecules\n"
     ]
    }
   ],
   "source": [
    "print(f\"the data is comprised of {len(dataset)} molecules\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf0a6af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default scaffold splitting is done 80% train | 10% valid | 10% test\n"
     ]
    }
   ],
   "source": [
    "# default scaffold splitting\n",
    "split_idx = dataset.get_idx_split() \n",
    "train_idx, valid_idx, test_idx = split_idx[\"train\"], split_idx[\"valid\"], split_idx[\"test\"]\n",
    "print(f\"default scaffold splitting is done {round(len(train_idx)/len(dataset)*100)}% train | {round(len(valid_idx)/len(dataset)*100)}% valid | {round(len(test_idx)/len(dataset)*100)}% test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64678270",
   "metadata": {},
   "source": [
    "#### Label Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c08eef57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1443 positive labels in 41127 data points (3.5%)\n"
     ]
    }
   ],
   "source": [
    "# ...\n",
    "count = 0\n",
    "for i in range(len(dataset)):\n",
    "    count += dataset[i][1]\n",
    "print(f\"{int(count)} positive labels in {len(dataset)} data points ({round(int(count)*100/len(dataset),1)}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1a07968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1232 positive labels in 32901 training data points (3.7%)\n"
     ]
    }
   ],
   "source": [
    "# across splits: training\n",
    "count = 0\n",
    "for i in range(len(dataset[split_idx[\"train\"]])):\n",
    "    count += dataset[split_idx[\"train\"][i]][1]\n",
    "\n",
    "print(f\"{int(count)} positive labels in {len(dataset[split_idx['train']])} training data points ({round(int(count)*100/len(dataset[split_idx['train']]),1)}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d2c4a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81 positive labels in 4113 training data points (2.0%)\n"
     ]
    }
   ],
   "source": [
    "# across splits: validation\n",
    "count = 0\n",
    "for i in range(len(dataset[split_idx[\"valid\"]])):\n",
    "    count += dataset[split_idx[\"valid\"][i]][1]\n",
    "\n",
    "print(f\"{int(count)} positive labels in {len(dataset[split_idx['valid']])} training data points ({round(int(count)*100/len(dataset[split_idx['valid']]), 1)}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7c9838b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 positive labels in 4113 training data points (3.2%)\n"
     ]
    }
   ],
   "source": [
    "# across splits: test\n",
    "count = 0\n",
    "for i in range(len(dataset[split_idx[\"test\"]])):\n",
    "    count += dataset[split_idx[\"test\"][i]][1]\n",
    "\n",
    "print(f\"{int(count)} positive labels in {len(dataset[split_idx['test']])} training data points ({round(int(count)*100/len(dataset[split_idx['test']]), 1)}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7e172b",
   "metadata": {},
   "source": [
    "### Featurization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66000bfd",
   "metadata": {},
   "source": [
    "The ogbg-molhiv dataset comes with a SMILES string representation for eahc molecule.\n",
    "\n",
    "Based on the SMILES representation, descriptor calculators such as PaDEL-Descriptor can calculate descriptors and fingerprints as features.\n",
    "\n",
    "\"\"The molecular descriptor is the final result of a logic and mathematical procedure which transforms chemical information encoded within a symbolic representation of a molecule into a useful number or the result of some standardized experiment.\"\n",
    "\n",
    "Descriptors and fingerprints represent human feature engineering.\n",
    "\n",
    "This way, there is the original graph data, but also a tabular counterpart which featurized the underlying molecule based on its SMILES string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db6d6b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare SMILES input for PaDEL-descriptor by creating a folder with .smi files\n",
    "# if run for the 1st time, creates \"ogbg-molhiv SMILES\" folder in \"data\" folder\n",
    "create_smiles_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ce872b",
   "metadata": {},
   "source": [
    "The resulting folder is the input for the PaDEL-Descriptor program.\n",
    "\n",
    "Due to problems with PaDEL-Descriptor's Python wrapper (padelpy), the calculation was done in 1 run in the PaDEL-Descriptor  with the following settings, resulting in ```1D_2D_PubChemFP_SubFP_full_raw.csv```.\n",
    "\n",
    "- 1D & 2D:          CHECK\n",
    "- 3D:               -\n",
    "- Fingerprints:     CHECK (PubChemFingerprinter + SubstructureFingerprinter)\n",
    "- Remove salt:      CHECK\n",
    "- Detect arom:      CHECK\n",
    "- Stand. tautomers: -\n",
    "- Stand. nitro:     CHECK\n",
    "- Retain 3D coord.: -\n",
    "- Convert to 3D:    No\n",
    "\n",
    "Also, max. running time was set to 30,000 ms. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2586dcd7",
   "metadata": {},
   "source": [
    "Resulting .csv file should be named \"featurized data/1D_2D_PubChemFP_SubFP_no-order_30s.csv\" and saved into a newly created \"featurized data\" folder in the \"data\" folder\n",
    "\n",
    "The file can also be downloader here: https://drive.google.com/file/d/1fRXMgHEO-bHSyZhjeGmduNjQin-VQI_J/view?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5e2f54",
   "metadata": {},
   "source": [
    "### Preprocessing of Featurized Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3c29f60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving file ...\n",
      "saved to 'raw data/1D_2D_PubChemFP_SubFP_raw.csv'\n"
     ]
    }
   ],
   "source": [
    "# get the data\n",
    "df_raw = handle_raw_data(\"featurized data/1D_2D_PubChemFP_SubFP_no-order_30s.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2d919973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41127, 2633)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load raw featurized data\n",
    "df_raw = pd.read_csv(\"featurized data/1D_2D_PubChemFP_SubFP_no-order_30s.csv\")\n",
    "df_raw.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85283f6f",
   "metadata": {},
   "source": [
    "The featurization process yielded 2632 descriptors (label included in 2633)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2abb817",
   "metadata": {},
   "source": [
    "Now, we can apply basic preprocessing steps.\n",
    "\n",
    "1. remove features with missing values and low variance (<0.05)\n",
    "2. remove features with high correlations (r>0.95) with other features\n",
    "3. standardization to mean value of 0 and variance of 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "16f22d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing resulted in 233 standardized features\n",
      "saving file ...\n",
      "saved to 'preprocessed data/1D_2D_PubChemFP_SubFP_preprocessed.csv'\n"
     ]
    }
   ],
   "source": [
    "# get processed data\n",
    "df_prepro = get_processed_data(\"raw data/1D_2D_PubChemFP_SubFP_raw.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "21290898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41127, 234)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load preprocessed data\n",
    "df_prepro = pd.read_csv(\"preprocessed data/1D_2D_PubChemFP_SubFP_preprocessed.csv\")\n",
    "df_prepro.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15395e6e",
   "metadata": {},
   "source": [
    "Now, we are only left with 233 features (234 including label)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d254def2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "x_train, y_train, x_valid, y_valid, x_test, y_test = get_split_data((\"preprocessed data/1D_2D_PubChemFP_SubFP_preprocessed.csv\"))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "05a6106fea09248b97928b45a8f993ed9eda1dddec2745a1933e0c85e248786f"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('GNN_thesis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
